{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Different feature extraction techniques were tested:\\n   - Raw pixel values\\n   - Histogram of Oriented Gradients (HOG) with Histogram Equalization ✅ (Best)\\n   - Local Binary Patterns (LBP)\\n   - PCA for dimensionality reduction\\n   - Canny Edge Detection + HOG\\n\\n2. Among these, HOG with histogram equalization provided the best performance.\\n\\n3. The final workflow includes:\\n   - Loading and preprocessing images\\n   - Extracting features using HOG\\n   - Standardizing the feature set\\n   - Training SVM and MLP classifiers\\n   - Evaluating accuracy and performance\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Work Done - Summary of Approaches Tried\n",
    "\"\"\"\n",
    "1. Different feature extraction techniques were tested:\n",
    "   - Raw pixel values\n",
    "   - Histogram of Oriented Gradients (HOG) with Histogram Equalization ✅ (Best)\n",
    "   - Local Binary Patterns (LBP)\n",
    "   - PCA for dimensionality reduction\n",
    "   - Canny Edge Detection + HOG\n",
    "\n",
    "2. Among these, HOG with histogram equalization provided the best performance.\n",
    "\n",
    "3. The final workflow includes:\n",
    "   - Loading and preprocessing images\n",
    "   - Extracting features using HOG\n",
    "   - Standardizing the feature set\n",
    "   - Training SVM and MLP classifiers\n",
    "   - Evaluating accuracy and performance\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load images and labels\n",
    "def load_images_from_folder(folder, label):\n",
    "    images, labels = [], []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))  # Resize for consistency\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "mask_images, mask_labels = load_images_from_folder(\"FaceMaskDetection_dataset/with_mask\", label=1)\n",
    "no_mask_images, no_mask_labels = load_images_from_folder(\"FaceMaskDetection_dataset/without_mask\", label=0)\n",
    "\n",
    "# Combine data\n",
    "X = np.array(mask_images + no_mask_images)\n",
    "y = np.array(mask_labels + no_mask_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Histogram of Oriented Gradients (HOG) \n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Histogram Equalization for Improved Contrast\n",
    "        gray = cv2.equalizeHist(gray)\n",
    "\n",
    "        # Optimized HOG Parameters\n",
    "        hog_features = hog(\n",
    "            gray,\n",
    "            orientations=9,                  # Balanced gradient directions\n",
    "            pixels_per_cell=(8, 8),          # Optimal for face detection\n",
    "            cells_per_block=(2, 2),          # Stronger feature stability\n",
    "            block_norm='L2-Hys',            \n",
    "            feature_vector=True\n",
    "        )\n",
    "        features.append(hog_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# 2. Local Binary Patterns (LBP)\n",
    "def extract_lbp_features(images, P=8, R=1):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        lbp = local_binary_pattern(img, P, R, method=\"uniform\")\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, P + 3), range=(0, P + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= hist.sum()  # Normalize histogram\n",
    "        features.append(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "# 3. PCA for Dimensionality Reduction\n",
    "def apply_pca(features, n_components=50):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(features)\n",
    "\n",
    "# 4. Canny Edge Detection + HOG\n",
    "def extract_canny_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        edges = cv2.Canny(img, 100, 200)  # Apply Canny edge detection\n",
    "        hog_feature = hog(edges, pixels_per_cell=(8, 8), cells_per_block=(2, 2), orientations=9, visualize=False)\n",
    "        features.append(hog_feature)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "\n",
    "# Extract features using HOG\n",
    "X_hog = extract_hog_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_hog, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM Classifier ===\n",
      "Accuracy: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       386\n",
      "           1       0.93      0.95      0.94       433\n",
      "\n",
      "    accuracy                           0.94       819\n",
      "   macro avg       0.94      0.93      0.93       819\n",
      "weighted avg       0.94      0.94      0.94       819\n",
      "\n",
      "=== MLP Classifier ===\n",
      "Accuracy: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       386\n",
      "           1       0.92      0.95      0.94       433\n",
      "\n",
      "    accuracy                           0.93       819\n",
      "   macro avg       0.93      0.93      0.93       819\n",
      "weighted avg       0.93      0.93      0.93       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Train and Evaluate Models\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Standardizing Features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # SVM Classifier\n",
    "    svm_model = SVC(kernel='rbf', C=10, gamma='auto')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "    # MLP Classifier\n",
    "    mlp_model = MLPClassifier(hidden_layer_sizes=(256, 128, 64), \n",
    "                              activation='relu', \n",
    "                              max_iter=1000, \n",
    "                              random_state=42)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"=== SVM Classifier ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "    print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "    print(\"=== MLP Classifier ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_mlp):.2f}\")\n",
    "    print(classification_report(y_test, y_pred_mlp))\n",
    "    \n",
    "    return svm_model, mlp_model, scaler, y_pred_svm, y_pred_mlp\n",
    "\n",
    "# Train and evaluate models\n",
    "svm_model, mlp_model, scaler, y_pred_svm, y_pred_mlp = train_and_evaluate(X_train, X_test, y_train, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
