{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data Paths\n",
    "data_dir = \"data/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['with_mask', 'without_mask']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(150, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load Dataset using ImageFolder\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Split Dataset into Train & Test (80%-20%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Data Loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Class Names\n",
    "class_names = dataset.classes\n",
    "print(f\"Classes: {class_names}\")  # ['with_mask', 'without_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.5640, Val Loss: 0.2472, Val Acc: 0.91\n",
      "Epoch [2/15], Train Loss: 0.2024, Val Loss: 0.1743, Val Acc: 0.93\n",
      "Epoch [3/15], Train Loss: 0.1554, Val Loss: 0.1555, Val Acc: 0.94\n",
      "Epoch [4/15], Train Loss: 0.1354, Val Loss: 0.1523, Val Acc: 0.95\n",
      "Epoch [5/15], Train Loss: 0.1331, Val Loss: 0.1596, Val Acc: 0.95\n",
      "Epoch [6/15], Train Loss: 0.1113, Val Loss: 0.1658, Val Acc: 0.94\n",
      "Epoch [7/15], Train Loss: 0.1003, Val Loss: 0.1521, Val Acc: 0.96\n",
      "Epoch [8/15], Train Loss: 0.1099, Val Loss: 0.1806, Val Acc: 0.94\n",
      "Epoch [9/15], Train Loss: 0.1019, Val Loss: 0.1097, Val Acc: 0.96\n",
      "Epoch [10/15], Train Loss: 0.1036, Val Loss: 0.1293, Val Acc: 0.96\n",
      "Epoch [11/15], Train Loss: 0.0834, Val Loss: 0.1138, Val Acc: 0.96\n",
      "Epoch [12/15], Train Loss: 0.0915, Val Loss: 0.1372, Val Acc: 0.94\n",
      "Epoch [13/15], Train Loss: 0.0812, Val Loss: 0.1226, Val Acc: 0.96\n",
      "Epoch [14/15], Train Loss: 0.0640, Val Loss: 0.1101, Val Acc: 0.96\n",
      "Epoch [15/15], Train Loss: 0.0565, Val Loss: 0.1587, Val Acc: 0.96\n",
      "Early stopping triggered at epoch 15\n",
      "Loaded best model weights.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MaskCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(100, 100, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(100 * 37 * 37, 50)  # Adjusted for image size\n",
    "        self.fc2 = nn.Linear(50, 2)  # 2 classes: With Mask & Without Mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten\n",
    "        # x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_validation_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_validation_loss - self.min_delta:\n",
    "            self.best_validation_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss > self.best_validation_loss + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Assuming 'device', 'train_loader', and 'test_loader' are already defined\n",
    "\n",
    "# Initialize Model\n",
    "model = MaskCNN().to(device)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Since we have 2 classes (softmax output)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early Stopping Initialization\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "min_delta = 0.001 # Minimum change in validation loss to consider as improvement\n",
    "early_stopper = EarlyStopper(patience=patience, min_delta=min_delta)\n",
    "\n",
    "# Training the Model\n",
    "num_epochs = 15  # Increased max epochs to allow for early stopping\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation Step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy Calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    val_loss /= len(test_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}\")\n",
    "\n",
    "    # Early Stopping Check\n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        torch.save(best_model_state, \"best_mask_model.pth\")\n",
    "\n",
    "# Load the best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model weights.\")\n",
    "else:\n",
    "    print(\"No improvement found during training, using the last trained model.\")\n",
    "\n",
    "# Optionally save the final model (which might not be the best)\n",
    "torch.save(model.state_dict(), \"final_mask_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "# Final Evaluation on Training Set\n",
    "model.eval()\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch Env )",
   "language": "python",
   "name": "pytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
